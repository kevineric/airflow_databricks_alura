{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "29650fba-faff-4783-a30b-c0bebb3557bb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.widgets.text(\"data_execucao\", \"\")\n",
    "data_execucao = dbutils.widgets.get(\"data_execucao\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3e81c126-8098-491f-bf10-1781145ddb55",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from pyspark.sql.functions import lit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "205b741f-925e-4268-bb8b-e52ce3a6f941",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def extraindo_dados(date,base=\"BRL\"):\n",
    "\n",
    "    url = f\"https://api.apilayer.com/exchangerates_data/{date}&base={base}\"\n",
    "\n",
    "\n",
    "    headers= {\n",
    "    \"apikey\": \"fR8DrYsTxX4yLyzcqsEHblpBFuhwev3e\"\n",
    "    }\n",
    "\n",
    "    parametros = {\"base\": base}\n",
    "\n",
    "    response = requests.request(\"GET\", url, headers=headers, params=parametros)\n",
    "\n",
    "    if response.status_code !=200:\n",
    "        raise Exception(\"Erro ao extrair os dados!!!\")\n",
    "    \n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "51e3e5eb-e597-42c2-b386-bf75c1157114",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def dados_para_dataframe (dado_json): \n",
    "        dados_tupla = [(moeda, float (taxa)) for moeda, taxa in dado_json[\"rates\"].items()]\n",
    "        return dados_tupla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e513aba3-5689-44b0-8214-7b2625671c88",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def salvar_arquivo_parquet(conversoes_extraidas):\n",
    "    ano, mes, dia = conversoes_extraidas['date'].split(\"-\")\n",
    "    caminho_completo = f\"dbfs:/databricks-results/bronze/{ano}/{mes}/{dia}\"\n",
    "    response = dados_para_dataframe(conversoes_extraidas)\n",
    "    df_conversoes = spark.createDataFrame(response, schema=['moeda','taxa'])\n",
    "    df_conversoes = df_conversoes.withColumn(\"data\", lit(f\"{ano}-{mes}-{dia}\"))\n",
    "    \n",
    "    df_conversoes.write.format(\"parquet\")\\\n",
    "            .mode(\"overwrite\")\\\n",
    "            .save(caminho_completo)\n",
    "\n",
    "    print(f\"Arquivos salvos em {caminho_completo}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ec37e0fb-4417-4d11-a30d-5ce7a6190086",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivos salvos em dbfs:/databricks-results/bronze/2024/01/01\n"
     ]
    }
   ],
   "source": [
    "cotacoes = extraindo_dados(data_execucao)\n",
    "salvar_arquivo_parquet(cotacoes)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "1-Extraindo-dados",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
